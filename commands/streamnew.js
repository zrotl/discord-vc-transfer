//const Discord = require('discord.js');
//const { SlashCommandBuilder, ChannelType } = require('discord.js');
//const { joinVoiceChannel, createAudioPlayer, NoSubscriberBehavior, EndBehaviorType, createAudioResource, StreamType } = require('@discordjs/voice');
//const AudioMixer = require('node-audio-mixer');
//const Prism = require('prism-media');
//const { PassThrough } = require('stream');

import { Client, SlashCommandBuilder, ChannelType } from 'discord.js';
import { VoiceConnectionStatus, joinVoiceChannel, createAudioPlayer, NoSubscriberBehavior, EndBehaviorType, createAudioResource, StreamType } from '@discordjs/voice';
import { AudioMixer } from 'node-audio-mixer';
import Prism from 'prism-media';
import { PassThrough } from 'stream';

// const Client = new Client();

export default {
	data: new SlashCommandBuilder()
        // ã‚³ãƒžãƒ³ãƒ‰ã®åå‰
		.setName('streamnew')
        // ã‚³ãƒžãƒ³ãƒ‰ã®èª¬æ˜Žæ–‡
		.setDescription('VCã‚’ä¸­ç¶™ã€‚')
		// ã‚³ãƒžãƒ³ãƒ‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
		.addChannelOption((option) =>
			option
				.setName('channel1')
				.setDescription('The channel that Listener-bot join')
				.setRequired(true)
				.addChannelTypes(ChannelType.GuildVoice),
		)
		.addStringOption((option) =>
			option
				.setName('channel2')
				.setDescription('The channel that Speaker-bot join')
				.setAutocomplete(true)
				.setRequired(true),
		),
	async autocomplete(interaction) {
		const focusedValue = interaction.options.getFocused();
		const vc = interaction.options.get('channel1');
		const chats = interaction.guild.channels.cache;
		const voiceChannels = chats.filter(file => file.type === 2);
		let unSelectedVoiceChannels = [];

		for (const voiceChannel of voiceChannels) {
			if (voiceChannel[0] !== vc.value) {
				unSelectedVoiceChannels.push(voiceChannel);
			}
		}
		
		const filtered = unSelectedVoiceChannels.filter(unSelectedVoiceChannel => unSelectedVoiceChannel[1].name.startsWith(focusedValue));

		await interaction.respond(
			
			filtered.map(unSelectedVoiceChannel => ({ name: unSelectedVoiceChannel[1].name, value: unSelectedVoiceChannel[1].id })).slice(0, 25)
		);
	},
	async execute(interaction, client1, client2) {
		const voiceChannel1 = interaction.options.getChannel('channel1');
		const voiceChannel2 = interaction.options.getString('channel2');
		const memberList = new Map();
		if (voiceChannel1 && voiceChannel2) {
			if (voiceChannel1 === voiceChannel2) {
				await interaction.reply('åŒã˜VCã«ã¯å‚åŠ ã§ãã¾ã›ã‚“ðŸ¥º');
				return;
			}
			// Listener-botãŒVCã«å‚åŠ ã™ã‚‹å‡¦ç†
			const connection1 = joinVoiceChannel({
				// ãªãœã‹ã¯ã‚ã‹ã‚‰ãªã„ãŒã€groupã®æŒ‡å®šã‚’ã—ãªã„ã¨ã€å…ˆã«VCã«å…¥ã£ã¦ã„ã‚‹BOTãŒVCã‚’ç§»å‹•ã™ã‚‹ã ã‘ã«ãªã£ã¦ã—ã¾ã†ã®ã§ã€è¨˜è¿°ã€‚
				group: 'listener',
				guildId: interaction.guildId,
				channelId: voiceChannel1.id,
				// ã©ã£ã¡ã®BOTã‚’å‹•ã‹ã—ã¦ã‚ã’ã‚‹ã‹ã®æŒ‡å®šã‚’ã—ã¦ã‚ã’ã‚‹ã€‚
				adapterCreator: client1.guilds.cache.get(interaction.guildId).voiceAdapterCreator,
				// VCå‚åŠ æ™‚ã«ãƒžã‚¤ã‚¯ãƒŸãƒ¥ãƒ¼ãƒˆã€ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒŸãƒ¥ãƒ¼ãƒˆã«ã™ã‚‹ã‹å¦ã‹
				selfMute: true,
				selfDeaf: false,
			});
			// Speaker-botãŒVCã«å‚åŠ ã™ã‚‹å‡¦ç†
			const connection2 = joinVoiceChannel({
				group: 'speaker',
				guildId: interaction.guildId,
				channelId: voiceChannel2,
				adapterCreator: client2.guilds.cache.get(interaction.guildId).voiceAdapterCreator,
				selfMute: false,
				selfDeaf: true,
			});

			const mixer = new AudioMixer({
				sampleRate: 48000,
				bitDepth: 16,
				channels: 2,
				generateSilent: true,
				autoClose: false,
			});
			// éŸ³å£°ã‚’VCã«æµã™æ©Ÿèƒ½
			const player = createAudioPlayer({
				behaviors: {
					// èžã„ã¦ã„ã‚‹äººãŒã„ãªãã¦ã‚‚éŸ³å£°ã‚’ä¸­ç¶™ã—ã¦ãã‚Œã‚‹ã‚ˆã†ã«è¨­å®š
					noSubscriber: NoSubscriberBehavior.play,
				},
			});
			const resource = createAudioResource(mixer,
				{
					inputType: StreamType.Raw,
                    //silencePaddingFrames: -1,
				},
			);
			player.play(resource);
			connection2.subscribe(player);

			connection2.on(VoiceConnectionStatus.Destroyed, () => {
				memberList.forEach((voice) => {
					if (voice !== undefined && voice !== null) voice.destroy();
				})
				mixer.close();
			});

			//TODO:client1ãŒVCã«å…¥ã£ãŸæ™‚ã€ã™ã§ã«å…¥ã£ã¦ã„ãŸmemberã®åˆ†ã®AudioInputã‚’ä½œæˆã™ã‚‹
			//voiceChannel1.members.filter(user => !user.bot).each(user => {
			voiceChannel1.members.each(user => {
				if (user.id === client1.user.id) return;
				memberList.set(user.id, createUserAudioStream(connection1, mixer, user.id));
			});

			//TODO:ã“ã“client1ã§ã„ã„ã®ï¼Ÿ
            client1.on("voiceStateUpdate", (oldState, newState) => {
				if (oldState.channelId === voiceChannel1.id && newState.channelId === null) {
					//disconnect from VC Event
					console.log('disconnect user: '+oldState.member.user.id);
					if (oldState.member.user.id === client1.user.id) return;
					const voice = memberList.get(oldState.member.user.id);
					if (voice !== undefined && voice !== null) voice.destroy();
					memberList.delete(oldState.member.user.id);
				} else if (oldState.channelId === null && newState.channelId === voiceChannel1.id) {
					//connect to VC Event
					console.log('connect user: '+newState.member.user.id);
					if (newState.member.user.id === client1.user.id) return;
					memberList.set(newState.member.user.id, createUserAudioStream(connection1, mixer, newState.member.user.id));
				}
            });

			await interaction.reply('VCã‚’ä¸­ç¶™ã—ã¾ã™ï¼');
			return [connection1, connection2];
		}
		// autocompleteä¸ä½¿ç”¨æ™‚ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’è§£é™¤
		// else {
		// 	await interaction.reply('BOTã‚’å‚åŠ ã•ã›ã‚‹VCã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼');
		// }
	},
};

function createUserAudioStream(connection, mixer, userid) {
	const userInput = mixer.createAudioInput({
		sampleRate: 48000,
		bitDepth: 16,
		channels: 2,
		forceClose: true,
	});

	const voice = connection.receiver.subscribe(userid, {
		end: { behavior: EndBehaviorType.Manual, },
	});
	const rawStream = new PassThrough();
	voice
		.pipe(new Prism.opus.Decoder({ rate: 48000, channels: 2, frameSize: 960 }))
		.pipe(rawStream);
	const p = rawStream.pipe(userInput);
	rawStream.on('end', () => {
		if (mixer != null) {
			mixer.removeAudioInput(userInput);
			userInput.close(); //automatically removed from audioMixer.
			rawStream.destroy();
			p.destroy();
		}
	});
	console.log('create user AudioStream: '+userid);
	return voice;
}